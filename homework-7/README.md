# Многопоточный индексатор логов

## Цель

Реализовать консольное приложение на **C++**, которое в многопоточном режиме строит частотный индекс слов по набору больших текстовых файлов (логов).

Задача направлена на проверку навыков:

* работы с потоками (`std::thread`)
* синхронизации (`std::mutex`, `std::condition_variable`, `std::atomic`)
* проектирования producer–consumer архитектуры
* оптимизации производительности

---

## Входные данные

1. **Каталог с текстовыми файлами**

   * Количество файлов: `N ≥ 1`
   * Размер файлов: от нескольких мегабайт до сотен мегабайт
   * Кодировка: ASCII / UTF-8 (без обязательной поддержки Unicode-слов)

2. **Параметры командной строки**

```text
--threads K   количество рабочих потоков (K ≥ 1)
--top M       количество самых частых слов для вывода (M ≥ 1)
--minlen L    минимальная длина слова (L ≥ 1)
<path>        путь к каталогу с файлами
```

Пример запуска:

```bash
./indexer --threads 8 --top 20 --minlen 3 ./data
```

---

## Определение слова

* Слово состоит из символов:

  * латинские буквы `a–z`, `A–Z`
  * цифры `0–9`
  * символ `_`
* Все остальные символы считаются разделителями
* Слова приводятся к **нижнему регистру**
* Слова длиной меньше `minlen` игнорируются

Пример:

```text
"Error_code=404 at user_123" → error_code, 404, at, user_123
```

(при `minlen = 3` слово `at` будет отброшено)

---

## Требования к реализации

### 1. Архитектура

Программа должна быть построена по схеме **producer–consumer**:

* **Producer (1 поток)**:

  * обходит каталог
  * находит файлы
  * помещает пути к файлам в потокобезопасную очередь задач

* **Consumers (K потоков)**:

  * извлекают файлы из очереди
  * читают файлы построчно
  * извлекают слова
  * считают частоты

Очередь должна:

* быть потокобезопасной
* корректно завершать работу consumers после окончания producer’а
* не использовать busy-wait.

---

### 2. Подсчёт частот

* **Запрещено** использовать один глобальный `mutex` на каждую операцию инкремента счётчика слова
* Рекомендуемый подход:

  * у каждого worker-потока есть **локальная** `unordered_map<string, uint64_t>`
  * периодически или после обработки файла результаты сливаются в глобальную структуру

Возможные варианты глобальной структуры:

* одна мапа + редкий merge под mutex
* шардированная мапа (несколько сегментов с отдельными mutex)

---

### 3. Завершение работы

Программа должна корректно:

* обработать все файлы
* завершить все потоки
* освободить ресурсы
* корректно работать при `K = 1`

---

## Выходные данные

* Вывести `M` самых частых слов:

```text
<слово> <количество>
```

* Сортировка:

  1. по убыванию частоты
  2. при равенстве — лексикографически по слову

Пример:

```text
error 1245321
info  932114
user_123 53211
```

---

## Ограничения

* Использовать стандартную библиотеку C++ (C++17 или новее)
* Запрещено использовать сторонние thread pool библиотеки
* Допускается использование `std::filesystem`

---

## Критерии оценки

1. **Корректность**

   * отсутствие data race
   * корректное завершение потоков

2. **Производительность**

   * заметное ускорение при увеличении числа потоков
   * отсутствие глобальных узких мест

3. **Качество кода**

   * читаемая архитектура
   * разумное разделение ответственности

---

## Дополнительные задания (по желанию)

* Прогресс-бар (через `std::atomic`)
* Обработка сигнала завершения (Ctrl+C)
* Ограничение памяти
* Поддержка UTF-8 слов
* Сравнение производительности разных стратегий синхронизации

---

## Примечание

Для тестирования рекомендуется использовать отдельную программу-генератор логов, создающую большие файлы со скошенным распределением частот слов.
